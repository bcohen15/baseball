{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import csv\n",
    "import os\n",
    "import os.path\n",
    "import datetime\n",
    "import re\n",
    "import time\n",
    "import pandas as pd\n",
    "import psycopg2\n",
    "from sqlalchemy import create_engine, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tomorrow(date):\n",
    "    \"\"\"function to return tomorrow's date\"\"\"\n",
    "    # converts string to datetime and increments by one day\n",
    "    date = datetime.datetime.strptime(date,'%Y-%m-%d') + datetime.timedelta(days=1)\n",
    "    # converts datetime object to a string\n",
    "    date = datetime.datetime.strftime(date,'%Y-%m-%d')\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def double_headers(l):\n",
    "    df = pd.DataFrame(l, columns = ['id','retro_game_id','date','team','home_away','time','opposing_team'])\n",
    "    df['id_count'] = df.groupby('id')['id'].transform('count')\n",
    "    df['max_time'] = df.groupby('id')['time'].transform('max')\n",
    "    \n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    for x in range(len(df)):\n",
    "        if (df['id_count'][x] == 4) & (df['time'][x] != df['max_time'][x]):\n",
    "            l1.append(df['id'][x]+'1')\n",
    "            l2.append(df['retro_game_id'][x]+'1')\n",
    "        elif (df['id_count'][x] == 4) & (df['time'][x] == df['max_time'][x]):\n",
    "            l1.append(df['id'][x]+'2')\n",
    "            l2.append(df['retro_game_id'][x]+'2')\n",
    "        else:\n",
    "            l1.append(df['id'][x]+'0')\n",
    "            l2.append(df['retro_game_id'][x]+'0')\n",
    "\n",
    "    df['id'] = l1\n",
    "    df['retro_game_id'] = l2\n",
    "    \n",
    "    df = df[['id','retro_game_id','date','team','home_away','time','opposing_team']]\n",
    "    \n",
    "    l3 = df.values.tolist()\n",
    "    \n",
    "    return l3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data(day):\n",
    "    \"\"\"function to return lineups for every game in day\"\"\"\n",
    "    \n",
    "    url = 'http://www.baseballpress.com/lineups/' + day\n",
    "    \n",
    "    # open up the file, get the web content and write it into a text file\n",
    "    response = urllib.request.urlopen(url)\n",
    "    webContent = response.read()\n",
    "    with open(day+'.txt', 'wb') as f1:\n",
    "        f1.write(webContent)\n",
    "    f1.close()\n",
    "\n",
    "    # open up the text file to read\n",
    "    with open(day +'.txt', 'rt') as f2:\n",
    "        file_lines = f2.readlines()\n",
    "        \n",
    "        # dictionary of team names and their appropriate abbreviation\n",
    "        team_dict = {'Blue Jays': 'TOR', 'Yankees': 'NYA', 'Twins': 'MIN', 'Tigers': 'DET', 'Rockies': \"COL\",\n",
    "                \"Brewers\": 'MIL', \"Red Sox\": \"BOS\", \"Phillies\": \"PHI\", \"Rays\": \"TBA\", \"Mets\": \"NYN\",\n",
    "                \"Nationals\": \"WAS\", \"Braves\": \"ATL\", 'Marlins': \"MIA\", \"White Sox\": \"CHA\", \"Royals\": 'KCA',\n",
    "                \"Angels\": \"ANA\", \"Mariners\": \"SEA\", \"Pirates\": \"PIT\", \"Astros\": \"HOU\", \"Reds\": \"CIN\",\n",
    "                \"Padres\": \"SDN\", \"Dodgers\": \"LAN\", \"Indians\": \"CLE\", \"Rangers\": \"TEX\", \"Athletics\": \"OAK\",\n",
    "                \"Giants\": \"SFN\", \"Diamondbacks\": \"ARI\", \"Cardinals\": \"SLN\", \"Cubs\": \"CHN\", \"Orioles\":\"BAL\"}\n",
    "\n",
    "        teams = []\n",
    "        teams_list = []\n",
    "\n",
    "        for i in range(0, len(file_lines)-1):\n",
    "            # finds the row to start to find the teams \n",
    "            # to make sure there was a game played that day (i.e. postponed due to rain)\n",
    "            if (\"</svg>\" in file_lines[i]) and (\"No Lineup Released\" not in file_lines[i:i+4]) and (\"PPD\" not in file_lines[i+5]) and (\"PPD\" not in file_lines[i-5]): \n",
    "                # split on these characters to get team name\n",
    "                team_name = re.split(\"<div>|</div>\",file_lines[i+1])[1]\n",
    "#                 \n",
    "                if (len(teams) % 2 == 0): # away team\n",
    "                    game_time = re.split(\"<div>|</div>\",file_lines[i+6])[1]\n",
    "                    #convert time to 24 hour format\n",
    "                    game_time = time.strptime(game_time, '%I:%M%p')\n",
    "                    game_time = time.strftime('%H:%M', game_time)\n",
    "                    teams_list.append([str(day).strip(), team_dict[team_name.strip()],'Away',game_time])\n",
    "                else: # home team\n",
    "                    game_time = re.split(\"<div>|</div>\",file_lines[i-4])[1]\n",
    "                    game_time = time.strptime(game_time, '%I:%M%p')\n",
    "                    game_time = time.strftime('%H:%M', game_time)\n",
    "                    teams_list.append([str(day).strip(), team_dict[team_name.strip()],'Home',game_time])\n",
    "                    \n",
    "                teams.append(team_dict[team_name])\n",
    "        \n",
    "        insert_at = 0       \n",
    "        # finds the opposing team name\n",
    "        # add a unique identifier for games\n",
    "        for x in range(len(teams_list)):\n",
    "            if teams_list[x][-2] == 'Away':\n",
    "                teams_list[x].append(teams_list[x+1][1])\n",
    "                #retro_game_id\n",
    "                teams_list[x][insert_at:insert_at] = [teams_list[x+1][1] + day.replace('-','')]\n",
    "                #game_id\n",
    "                teams_list[x][insert_at:insert_at] = [day.replace('-','') + teams_list[x+1][1] + teams_list[x][2]]\n",
    "            else:\n",
    "                teams_list[x].append(teams_list[x-1][3])\n",
    "                #retro_game_id\n",
    "                teams_list[x][insert_at:insert_at] = [teams_list[x][1] + day.replace('-','')]\n",
    "                #game_id\n",
    "                teams_list[x][insert_at:insert_at] = [day.replace('-','') + teams_list[x][2] + teams_list[x-1][3]]\n",
    "\n",
    "                \n",
    "        ##alter ids to account for double headers\n",
    "        teams_list = double_headers(teams_list)\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "        pitcher_list = []\n",
    "        for i in range(0, len(file_lines)-1):\n",
    "            # finds the row to start to find the pitchers\n",
    "            if (\"col col--min player\" in file_lines[i]) and (\"No Lineup Released\" not in file_lines[i:i+4]) and (\"PPD\" not in file_lines[i-11]) and (\"PPD\" not in file_lines[i-12]): #to make sure there is a team and lineup\n",
    "                    pitcher = re.split('<|>|=',file_lines[i])\n",
    "                    pitcher_list.append([\"\",pitcher[-5].strip(),pitcher[-3].strip(), \"Pitcher\",pitcher[7][:6],pitcher[10].split('\"')[1]])\n",
    "\n",
    "\n",
    "        hitter_list = []\n",
    "        for i in range(0, len(file_lines)-1):\n",
    "            # finds the row to start to find the hitters\n",
    "            if (\"col col--min\" in file_lines[i]) and (\"No Lineup Released\" not in file_lines[i:i+4]) and (\"PPD\" not in file_lines[i-17]) and (\"PPD\" not in file_lines[i-19]): #to make sure there is a team and lineup\n",
    "                    hitter = re.split('</div>|</a>',file_lines[i+1])\n",
    "                    for x in range(len(hitter)):\n",
    "                        if 'desktop-name' in hitter[x]:\n",
    "                            hitter_list.append([re.split('</span>|\">',hitter[x])[1][0],re.split('</span>|\">',hitter[x])[3], hitter[x+1].split(\" \")[1], hitter[x+1].split(\" \")[2], re.split('</span>|\">',hitter[x])[1][-6:]])\n",
    "                        elif '<div class=\"player\">' in hitter[x]:\n",
    "                            hitter_list.append([re.split('\">',hitter[x])[-2][0],re.split('\">',hitter[x])[-1], hitter[x+1].split(\" \")[1], hitter[x+1].split(\" \")[2], re.split('data-mlb=\"',hitter[x])[1][:6],re.split('data-bref=\"|\" data-razz',hitter[x])[1]])\n",
    "                        else:\n",
    "                            pass\n",
    "\n",
    "        data = []\n",
    "        # merges all three lists into a list of lists\n",
    "        for x in range(len(teams_list)):\n",
    "            # top and bottom are to slice the hitters list to retrieve that team's hitters\n",
    "            top = x*9\n",
    "            bottom = (x+1)*9\n",
    "            \n",
    "            # the * symbol concatenates the two lists into one rather a list of two sublists\n",
    "            # [1,2] and [3,4] = [1,2,3,4]\n",
    "            data.append([*teams_list[x],*pitcher_list[x]])\n",
    "            for y in range(top,bottom):\n",
    "                data.append([*teams_list[x],*hitter_list[y]])\n",
    "    \n",
    "    os.remove(str(day) + \".txt\")\n",
    "    f2.close()\n",
    "    \n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(start_date, end_date):\n",
    "    '''EX for day input: 2015-03-04 <-- YOU NEED THE 0s'''\n",
    "\n",
    "    cur_day = start_date\n",
    "    end_date_p1 = tomorrow(str(end_date))\n",
    "    \n",
    "    save_path = \"./Data\"\n",
    "\n",
    "    # dictionary of lineup data with the date being the key\n",
    "    all_data = {}\n",
    "\n",
    "    # run the function for every day in between the given dates\n",
    "    while (cur_day != end_date_p1): \n",
    "        try:\n",
    "            all_data[cur_day] = (aggregate_data(str(cur_day)))\n",
    "            cur_day = tomorrow(str(cur_day))\n",
    "\n",
    "        except Exception as e:\n",
    "            print(cur_day)\n",
    "            cur_day = tomorrow(str(cur_day))\n",
    "            print(str(e)) #for error checking\n",
    "                                        \n",
    "    try: # write the information that was stored in the data array\n",
    "        complete_name = os.path.join(save_path, start_date + '_' + end_date + '_lineups.csv')\n",
    "        with open(complete_name, 'wt') as k:\n",
    "\n",
    "            writer = csv.writer(k, delimiter = ',',lineterminator = \"\\n\")\n",
    "            # Header row\n",
    "            writer.writerow([\"id\",'retro_game_id',\"date\", \"team\", \"home_away\",'game_time',\"opposing_team\", \"order\", \"name\", 'handedness','position','mlb_id','bref_id'])\n",
    "            for day in all_data:\n",
    "                for row in range(len(all_data[day])):\n",
    "                    writer.writerow(all_data[day][row])\n",
    "\n",
    "                \n",
    "        k.close()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "main('2019-05-25','2019-05-25')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
